{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8171c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import import_ipynb\n",
    "import modelofuncoes as mf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1642e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametrosAB = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=410)\n",
    "\n",
    "hiperparametrosRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, \n",
    "                                           criterion='gini', max_depth=None, max_features='auto', \n",
    "                                           max_leaf_nodes=None, max_samples=None, \n",
    "                                           min_impurity_decrease=0.0,\n",
    "                                           min_samples_leaf=1, min_samples_split=2,\n",
    "                                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                           n_jobs=-1, oob_score=False, random_state=7374, verbose=0,\n",
    "                                           warm_start=False)\n",
    "\n",
    "hiperparametrosLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                                       intercept_scaling=1, l1_ratio=None, max_iter=1000, \n",
    "                                       multi_class='auto', n_jobs=None, penalty='l2', \n",
    "                                       random_state=2576, solver='lbfgs', tol=0.0001, verbose=0, \n",
    "                                       warm_start=False)\n",
    "                    \n",
    "\n",
    "hiperparametrosGB = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None,\n",
    "                           random_state=2333, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6921238",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "            \"AB\": hiperparametrosAB,\n",
    "            \"RF\": hiperparametrosRF,\n",
    "            \"LR\": hiperparametrosLR,\n",
    "            \"GB\": hiperparametrosGB,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5271ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = {\n",
    "    \"Sao Paulo - Lote 1 (60/40)\": \"SP/sp-l1-6040-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 1 (70/30)\": \"SP/sp-l1-7030-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 2 (60/40)\": \"SP/sp-l2-6040-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 2 (70/30)\": \"SP/sp-l2-7030-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 3 (60/40)\": \"SP/sp-l3-6040-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 3 (70/30)\": \"SP/sp-l3-7030-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 4 (60/40)\": \"SP/sp-l4-6040-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 4 (70/30)\": \"SP/sp-l4-7030-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 5 (60/40)\": \"SP/sp-l5-6040-2022.xlsx\",\n",
    "    \"Sao Paulo - Lote 5 (70/30)\": \"SP/sp-l5-7030-2022.xlsx\",   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3881382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo = 'evolucaoCaso'\n",
    "\n",
    "colunasRemovidas = ['disturbiosOlfativos', 'disturbiosGustatorios', 'puerpera', 'fragilidadeImuno', \n",
    "                    'gestante', 'obesidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375e730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converterMapas(baseMap, metricasMap, kfoldsMap):\n",
    "    baseMap.update(metricasMap)\n",
    "    baseMap.update(kfoldsMap)\n",
    "    return pd.DataFrame([baseMap])\n",
    "\n",
    "def juntarBases (base_1, base_2):\n",
    "    return pd.concat([base_1, base_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "605d46bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Hiperparâmetros</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Precisão (0)</th>\n",
       "      <th>Recall (0)</th>\n",
       "      <th>F1-Score (0)</th>\n",
       "      <th>Precisão (1)</th>\n",
       "      <th>Recall (1)</th>\n",
       "      <th>F1-Score (1)</th>\n",
       "      <th>3 Kfolds</th>\n",
       "      <th>5 Kfolds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (60/40)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>81.9%</td>\n",
       "      <td>74.545%</td>\n",
       "      <td>61.194%</td>\n",
       "      <td>67.213%</td>\n",
       "      <td>84.337%</td>\n",
       "      <td>90.909%</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>82.449%</td>\n",
       "      <td>83.673%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (60/40)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>82.805%</td>\n",
       "      <td>80.851%</td>\n",
       "      <td>56.716%</td>\n",
       "      <td>66.667%</td>\n",
       "      <td>83.333%</td>\n",
       "      <td>94.156%</td>\n",
       "      <td>88.415%</td>\n",
       "      <td>81.497%</td>\n",
       "      <td>82.449%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (60/40)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>83.71%</td>\n",
       "      <td>79.245%</td>\n",
       "      <td>62.687%</td>\n",
       "      <td>70.0%</td>\n",
       "      <td>85.119%</td>\n",
       "      <td>92.857%</td>\n",
       "      <td>88.82%</td>\n",
       "      <td>83.673%</td>\n",
       "      <td>85.034%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (60/40)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>83.258%</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>58.209%</td>\n",
       "      <td>67.826%</td>\n",
       "      <td>83.815%</td>\n",
       "      <td>94.156%</td>\n",
       "      <td>88.685%</td>\n",
       "      <td>83.81%</td>\n",
       "      <td>83.946%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (70/30)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>88.645%</td>\n",
       "      <td>81.579%</td>\n",
       "      <td>56.364%</td>\n",
       "      <td>66.667%</td>\n",
       "      <td>89.787%</td>\n",
       "      <td>96.789%</td>\n",
       "      <td>93.157%</td>\n",
       "      <td>85.167%</td>\n",
       "      <td>85.385%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (70/30)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>86.447%</td>\n",
       "      <td>70.455%</td>\n",
       "      <td>56.364%</td>\n",
       "      <td>62.626%</td>\n",
       "      <td>89.52%</td>\n",
       "      <td>94.037%</td>\n",
       "      <td>91.723%</td>\n",
       "      <td>83.519%</td>\n",
       "      <td>83.626%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (70/30)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>87.912%</td>\n",
       "      <td>80.556%</td>\n",
       "      <td>52.727%</td>\n",
       "      <td>63.736%</td>\n",
       "      <td>89.03%</td>\n",
       "      <td>96.789%</td>\n",
       "      <td>92.747%</td>\n",
       "      <td>85.716%</td>\n",
       "      <td>85.934%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 1 (70/30)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>86.447%</td>\n",
       "      <td>73.684%</td>\n",
       "      <td>50.909%</td>\n",
       "      <td>60.215%</td>\n",
       "      <td>88.511%</td>\n",
       "      <td>95.413%</td>\n",
       "      <td>91.832%</td>\n",
       "      <td>85.496%</td>\n",
       "      <td>85.604%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (60/40)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>82.796%</td>\n",
       "      <td>76.087%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>68.627%</td>\n",
       "      <td>85.0%</td>\n",
       "      <td>91.538%</td>\n",
       "      <td>88.148%</td>\n",
       "      <td>82.882%</td>\n",
       "      <td>83.681%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (60/40)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>83.333%</td>\n",
       "      <td>76.596%</td>\n",
       "      <td>64.286%</td>\n",
       "      <td>69.903%</td>\n",
       "      <td>85.612%</td>\n",
       "      <td>91.538%</td>\n",
       "      <td>88.476%</td>\n",
       "      <td>79.971%</td>\n",
       "      <td>78.666%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (60/40)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>86.022%</td>\n",
       "      <td>82.609%</td>\n",
       "      <td>67.857%</td>\n",
       "      <td>74.51%</td>\n",
       "      <td>87.143%</td>\n",
       "      <td>93.846%</td>\n",
       "      <td>90.37%</td>\n",
       "      <td>83.37%</td>\n",
       "      <td>84.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (60/40)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>82.258%</td>\n",
       "      <td>74.468%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>67.961%</td>\n",
       "      <td>84.892%</td>\n",
       "      <td>90.769%</td>\n",
       "      <td>87.732%</td>\n",
       "      <td>82.076%</td>\n",
       "      <td>81.258%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (70/30)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>87.446%</td>\n",
       "      <td>85.0%</td>\n",
       "      <td>59.649%</td>\n",
       "      <td>70.103%</td>\n",
       "      <td>87.958%</td>\n",
       "      <td>96.552%</td>\n",
       "      <td>92.055%</td>\n",
       "      <td>84.619%</td>\n",
       "      <td>85.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (70/30)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>83.983%</td>\n",
       "      <td>70.833%</td>\n",
       "      <td>59.649%</td>\n",
       "      <td>64.762%</td>\n",
       "      <td>87.432%</td>\n",
       "      <td>91.954%</td>\n",
       "      <td>89.636%</td>\n",
       "      <td>81.489%</td>\n",
       "      <td>80.055%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (70/30)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>85.714%</td>\n",
       "      <td>83.333%</td>\n",
       "      <td>52.632%</td>\n",
       "      <td>64.516%</td>\n",
       "      <td>86.154%</td>\n",
       "      <td>96.552%</td>\n",
       "      <td>91.057%</td>\n",
       "      <td>84.487%</td>\n",
       "      <td>84.231%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 2 (70/30)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>87.013%</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>63.158%</td>\n",
       "      <td>70.588%</td>\n",
       "      <td>88.71%</td>\n",
       "      <td>94.828%</td>\n",
       "      <td>91.667%</td>\n",
       "      <td>84.618%</td>\n",
       "      <td>83.445%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (60/40)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>82.456%</td>\n",
       "      <td>69.355%</td>\n",
       "      <td>58.108%</td>\n",
       "      <td>63.235%</td>\n",
       "      <td>86.099%</td>\n",
       "      <td>90.995%</td>\n",
       "      <td>88.479%</td>\n",
       "      <td>80.485%</td>\n",
       "      <td>81.024%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (60/40)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>82.105%</td>\n",
       "      <td>70.909%</td>\n",
       "      <td>52.703%</td>\n",
       "      <td>60.465%</td>\n",
       "      <td>84.783%</td>\n",
       "      <td>92.417%</td>\n",
       "      <td>88.435%</td>\n",
       "      <td>77.954%</td>\n",
       "      <td>78.593%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (60/40)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>82.807%</td>\n",
       "      <td>74.51%</td>\n",
       "      <td>51.351%</td>\n",
       "      <td>60.8%</td>\n",
       "      <td>84.615%</td>\n",
       "      <td>93.839%</td>\n",
       "      <td>88.989%</td>\n",
       "      <td>81.224%</td>\n",
       "      <td>81.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (60/40)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>83.158%</td>\n",
       "      <td>72.414%</td>\n",
       "      <td>56.757%</td>\n",
       "      <td>63.636%</td>\n",
       "      <td>85.903%</td>\n",
       "      <td>92.417%</td>\n",
       "      <td>89.041%</td>\n",
       "      <td>82.595%</td>\n",
       "      <td>82.183%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (70/30)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>85.269%</td>\n",
       "      <td>75.926%</td>\n",
       "      <td>51.25%</td>\n",
       "      <td>61.194%</td>\n",
       "      <td>86.957%</td>\n",
       "      <td>95.238%</td>\n",
       "      <td>90.909%</td>\n",
       "      <td>84.926%</td>\n",
       "      <td>84.842%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (70/30)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>83.003%</td>\n",
       "      <td>67.241%</td>\n",
       "      <td>48.75%</td>\n",
       "      <td>56.522%</td>\n",
       "      <td>86.102%</td>\n",
       "      <td>93.04%</td>\n",
       "      <td>89.437%</td>\n",
       "      <td>81.858%</td>\n",
       "      <td>82.881%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (70/30)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>85.836%</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>61.538%</td>\n",
       "      <td>86.799%</td>\n",
       "      <td>96.337%</td>\n",
       "      <td>91.319%</td>\n",
       "      <td>85.01%</td>\n",
       "      <td>84.755%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 3 (70/30)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>84.703%</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>47.5%</td>\n",
       "      <td>58.462%</td>\n",
       "      <td>86.139%</td>\n",
       "      <td>95.604%</td>\n",
       "      <td>90.625%</td>\n",
       "      <td>84.158%</td>\n",
       "      <td>84.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (60/40)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>85.185%</td>\n",
       "      <td>75.439%</td>\n",
       "      <td>62.319%</td>\n",
       "      <td>68.254%</td>\n",
       "      <td>87.793%</td>\n",
       "      <td>93.035%</td>\n",
       "      <td>90.338%</td>\n",
       "      <td>83.983%</td>\n",
       "      <td>83.313%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (60/40)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>79.63%</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>50.725%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>84.112%</td>\n",
       "      <td>89.552%</td>\n",
       "      <td>86.747%</td>\n",
       "      <td>79.755%</td>\n",
       "      <td>79.975%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (60/40)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>85.185%</td>\n",
       "      <td>76.364%</td>\n",
       "      <td>60.87%</td>\n",
       "      <td>67.742%</td>\n",
       "      <td>87.442%</td>\n",
       "      <td>93.532%</td>\n",
       "      <td>90.385%</td>\n",
       "      <td>83.091%</td>\n",
       "      <td>83.758%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (60/40)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>85.185%</td>\n",
       "      <td>78.431%</td>\n",
       "      <td>57.971%</td>\n",
       "      <td>66.667%</td>\n",
       "      <td>86.758%</td>\n",
       "      <td>94.527%</td>\n",
       "      <td>90.476%</td>\n",
       "      <td>83.648%</td>\n",
       "      <td>83.647%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (70/30)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>86.228%</td>\n",
       "      <td>76.471%</td>\n",
       "      <td>53.425%</td>\n",
       "      <td>62.903%</td>\n",
       "      <td>87.986%</td>\n",
       "      <td>95.402%</td>\n",
       "      <td>91.544%</td>\n",
       "      <td>84.996%</td>\n",
       "      <td>85.539%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (70/30)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>83.533%</td>\n",
       "      <td>65.0%</td>\n",
       "      <td>53.425%</td>\n",
       "      <td>58.647%</td>\n",
       "      <td>87.591%</td>\n",
       "      <td>91.954%</td>\n",
       "      <td>89.72%</td>\n",
       "      <td>82.3%</td>\n",
       "      <td>82.304%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (70/30)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>86.527%</td>\n",
       "      <td>76.923%</td>\n",
       "      <td>54.795%</td>\n",
       "      <td>64.0%</td>\n",
       "      <td>88.298%</td>\n",
       "      <td>95.402%</td>\n",
       "      <td>91.713%</td>\n",
       "      <td>85.355%</td>\n",
       "      <td>85.809%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 4 (70/30)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>85.928%</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>53.425%</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>87.943%</td>\n",
       "      <td>95.019%</td>\n",
       "      <td>91.344%</td>\n",
       "      <td>85.085%</td>\n",
       "      <td>85.449%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (60/40)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>80.176%</td>\n",
       "      <td>77.551%</td>\n",
       "      <td>52.778%</td>\n",
       "      <td>62.81%</td>\n",
       "      <td>80.899%</td>\n",
       "      <td>92.903%</td>\n",
       "      <td>86.486%</td>\n",
       "      <td>81.481%</td>\n",
       "      <td>81.483%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (60/40)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>75.771%</td>\n",
       "      <td>68.085%</td>\n",
       "      <td>44.444%</td>\n",
       "      <td>53.782%</td>\n",
       "      <td>77.778%</td>\n",
       "      <td>90.323%</td>\n",
       "      <td>83.582%</td>\n",
       "      <td>77.91%</td>\n",
       "      <td>78.704%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (60/40)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>79.295%</td>\n",
       "      <td>75.51%</td>\n",
       "      <td>51.389%</td>\n",
       "      <td>61.157%</td>\n",
       "      <td>80.337%</td>\n",
       "      <td>92.258%</td>\n",
       "      <td>85.886%</td>\n",
       "      <td>81.349%</td>\n",
       "      <td>81.616%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (60/40)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>76.652%</td>\n",
       "      <td>74.359%</td>\n",
       "      <td>40.278%</td>\n",
       "      <td>52.252%</td>\n",
       "      <td>77.128%</td>\n",
       "      <td>93.548%</td>\n",
       "      <td>84.548%</td>\n",
       "      <td>80.688%</td>\n",
       "      <td>81.217%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (70/30)</td>\n",
       "      <td>AB</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>85.053%</td>\n",
       "      <td>71.111%</td>\n",
       "      <td>52.459%</td>\n",
       "      <td>60.377%</td>\n",
       "      <td>87.712%</td>\n",
       "      <td>94.091%</td>\n",
       "      <td>90.789%</td>\n",
       "      <td>85.043%</td>\n",
       "      <td>85.261%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (70/30)</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>81.495%</td>\n",
       "      <td>61.538%</td>\n",
       "      <td>39.344%</td>\n",
       "      <td>48.0%</td>\n",
       "      <td>84.711%</td>\n",
       "      <td>93.182%</td>\n",
       "      <td>88.745%</td>\n",
       "      <td>81.838%</td>\n",
       "      <td>82.267%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (70/30)</td>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>84.342%</td>\n",
       "      <td>71.795%</td>\n",
       "      <td>45.902%</td>\n",
       "      <td>56.0%</td>\n",
       "      <td>86.364%</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>90.476%</td>\n",
       "      <td>84.722%</td>\n",
       "      <td>84.084%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sao Paulo - Lote 5 (70/30)</td>\n",
       "      <td>GB</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>83.986%</td>\n",
       "      <td>71.053%</td>\n",
       "      <td>44.262%</td>\n",
       "      <td>54.545%</td>\n",
       "      <td>86.008%</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>90.281%</td>\n",
       "      <td>84.615%</td>\n",
       "      <td>85.153%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Base Modelo  \\\n",
       "0  Sao Paulo - Lote 1 (60/40)     AB   \n",
       "0  Sao Paulo - Lote 1 (60/40)     RF   \n",
       "0  Sao Paulo - Lote 1 (60/40)     LR   \n",
       "0  Sao Paulo - Lote 1 (60/40)     GB   \n",
       "0  Sao Paulo - Lote 1 (70/30)     AB   \n",
       "0  Sao Paulo - Lote 1 (70/30)     RF   \n",
       "0  Sao Paulo - Lote 1 (70/30)     LR   \n",
       "0  Sao Paulo - Lote 1 (70/30)     GB   \n",
       "0  Sao Paulo - Lote 2 (60/40)     AB   \n",
       "0  Sao Paulo - Lote 2 (60/40)     RF   \n",
       "0  Sao Paulo - Lote 2 (60/40)     LR   \n",
       "0  Sao Paulo - Lote 2 (60/40)     GB   \n",
       "0  Sao Paulo - Lote 2 (70/30)     AB   \n",
       "0  Sao Paulo - Lote 2 (70/30)     RF   \n",
       "0  Sao Paulo - Lote 2 (70/30)     LR   \n",
       "0  Sao Paulo - Lote 2 (70/30)     GB   \n",
       "0  Sao Paulo - Lote 3 (60/40)     AB   \n",
       "0  Sao Paulo - Lote 3 (60/40)     RF   \n",
       "0  Sao Paulo - Lote 3 (60/40)     LR   \n",
       "0  Sao Paulo - Lote 3 (60/40)     GB   \n",
       "0  Sao Paulo - Lote 3 (70/30)     AB   \n",
       "0  Sao Paulo - Lote 3 (70/30)     RF   \n",
       "0  Sao Paulo - Lote 3 (70/30)     LR   \n",
       "0  Sao Paulo - Lote 3 (70/30)     GB   \n",
       "0  Sao Paulo - Lote 4 (60/40)     AB   \n",
       "0  Sao Paulo - Lote 4 (60/40)     RF   \n",
       "0  Sao Paulo - Lote 4 (60/40)     LR   \n",
       "0  Sao Paulo - Lote 4 (60/40)     GB   \n",
       "0  Sao Paulo - Lote 4 (70/30)     AB   \n",
       "0  Sao Paulo - Lote 4 (70/30)     RF   \n",
       "0  Sao Paulo - Lote 4 (70/30)     LR   \n",
       "0  Sao Paulo - Lote 4 (70/30)     GB   \n",
       "0  Sao Paulo - Lote 5 (60/40)     AB   \n",
       "0  Sao Paulo - Lote 5 (60/40)     RF   \n",
       "0  Sao Paulo - Lote 5 (60/40)     LR   \n",
       "0  Sao Paulo - Lote 5 (60/40)     GB   \n",
       "0  Sao Paulo - Lote 5 (70/30)     AB   \n",
       "0  Sao Paulo - Lote 5 (70/30)     RF   \n",
       "0  Sao Paulo - Lote 5 (70/30)     LR   \n",
       "0  Sao Paulo - Lote 5 (70/30)     GB   \n",
       "\n",
       "                                     Hiperparâmetros Acurácia Precisão (0)  \\\n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...    81.9%      74.545%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  82.805%      80.851%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...   83.71%      79.245%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  83.258%       81.25%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  88.645%      81.579%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  86.447%      70.455%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  87.912%      80.556%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  86.447%      73.684%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  82.796%      76.087%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  83.333%      76.596%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  86.022%      82.609%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  82.258%      74.468%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  87.446%        85.0%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  83.983%      70.833%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  85.714%      83.333%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  87.013%        80.0%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  82.456%      69.355%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  82.105%      70.909%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  82.807%       74.51%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  83.158%      72.414%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  85.269%      75.926%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  83.003%      67.241%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  85.836%        80.0%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  84.703%        76.0%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  85.185%      75.439%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   79.63%        62.5%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  85.185%      76.364%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  85.185%      78.431%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  86.228%      76.471%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  83.533%        65.0%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  86.527%      76.923%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  85.928%        75.0%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  80.176%      77.551%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  75.771%      68.085%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  79.295%       75.51%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  76.652%      74.359%   \n",
       "0  {'algorithm': 'SAMME.R', 'base_estimator': Non...  85.053%      71.111%   \n",
       "0  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...  81.495%      61.538%   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...  84.342%      71.795%   \n",
       "0  {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...  83.986%      71.053%   \n",
       "\n",
       "  Recall (0) F1-Score (0) Precisão (1) Recall (1) F1-Score (1) 3 Kfolds  \\\n",
       "0    61.194%      67.213%      84.337%    90.909%        87.5%  82.449%   \n",
       "0    56.716%      66.667%      83.333%    94.156%      88.415%  81.497%   \n",
       "0    62.687%        70.0%      85.119%    92.857%       88.82%  83.673%   \n",
       "0    58.209%      67.826%      83.815%    94.156%      88.685%   83.81%   \n",
       "0    56.364%      66.667%      89.787%    96.789%      93.157%  85.167%   \n",
       "0    56.364%      62.626%       89.52%    94.037%      91.723%  83.519%   \n",
       "0    52.727%      63.736%       89.03%    96.789%      92.747%  85.716%   \n",
       "0    50.909%      60.215%      88.511%    95.413%      91.832%  85.496%   \n",
       "0      62.5%      68.627%        85.0%    91.538%      88.148%  82.882%   \n",
       "0    64.286%      69.903%      85.612%    91.538%      88.476%  79.971%   \n",
       "0    67.857%       74.51%      87.143%    93.846%       90.37%   83.37%   \n",
       "0      62.5%      67.961%      84.892%    90.769%      87.732%  82.076%   \n",
       "0    59.649%      70.103%      87.958%    96.552%      92.055%  84.619%   \n",
       "0    59.649%      64.762%      87.432%    91.954%      89.636%  81.489%   \n",
       "0    52.632%      64.516%      86.154%    96.552%      91.057%  84.487%   \n",
       "0    63.158%      70.588%       88.71%    94.828%      91.667%  84.618%   \n",
       "0    58.108%      63.235%      86.099%    90.995%      88.479%  80.485%   \n",
       "0    52.703%      60.465%      84.783%    92.417%      88.435%  77.954%   \n",
       "0    51.351%        60.8%      84.615%    93.839%      88.989%  81.224%   \n",
       "0    56.757%      63.636%      85.903%    92.417%      89.041%  82.595%   \n",
       "0     51.25%      61.194%      86.957%    95.238%      90.909%  84.926%   \n",
       "0     48.75%      56.522%      86.102%     93.04%      89.437%  81.858%   \n",
       "0      50.0%      61.538%      86.799%    96.337%      91.319%   85.01%   \n",
       "0      47.5%      58.462%      86.139%    95.604%      90.625%  84.158%   \n",
       "0    62.319%      68.254%      87.793%    93.035%      90.338%  83.983%   \n",
       "0    50.725%        56.0%      84.112%    89.552%      86.747%  79.755%   \n",
       "0     60.87%      67.742%      87.442%    93.532%      90.385%  83.091%   \n",
       "0    57.971%      66.667%      86.758%    94.527%      90.476%  83.648%   \n",
       "0    53.425%      62.903%      87.986%    95.402%      91.544%  84.996%   \n",
       "0    53.425%      58.647%      87.591%    91.954%       89.72%    82.3%   \n",
       "0    54.795%        64.0%      88.298%    95.402%      91.713%  85.355%   \n",
       "0    53.425%        62.4%      87.943%    95.019%      91.344%  85.085%   \n",
       "0    52.778%       62.81%      80.899%    92.903%      86.486%  81.481%   \n",
       "0    44.444%      53.782%      77.778%    90.323%      83.582%   77.91%   \n",
       "0    51.389%      61.157%      80.337%    92.258%      85.886%  81.349%   \n",
       "0    40.278%      52.252%      77.128%    93.548%      84.548%  80.688%   \n",
       "0    52.459%      60.377%      87.712%    94.091%      90.789%  85.043%   \n",
       "0    39.344%        48.0%      84.711%    93.182%      88.745%  81.838%   \n",
       "0    45.902%        56.0%      86.364%      95.0%      90.476%  84.722%   \n",
       "0    44.262%      54.545%      86.008%      95.0%      90.281%  84.615%   \n",
       "\n",
       "  5 Kfolds  \n",
       "0  83.673%  \n",
       "0  82.449%  \n",
       "0  85.034%  \n",
       "0  83.946%  \n",
       "0  85.385%  \n",
       "0  83.626%  \n",
       "0  85.934%  \n",
       "0  85.604%  \n",
       "0  83.681%  \n",
       "0  78.666%  \n",
       "0   84.01%  \n",
       "0  81.258%  \n",
       "0   85.14%  \n",
       "0  80.055%  \n",
       "0  84.231%  \n",
       "0  83.445%  \n",
       "0  81.024%  \n",
       "0  78.593%  \n",
       "0   81.97%  \n",
       "0  82.183%  \n",
       "0  84.842%  \n",
       "0  82.881%  \n",
       "0  84.755%  \n",
       "0   84.84%  \n",
       "0  83.313%  \n",
       "0  79.975%  \n",
       "0  83.758%  \n",
       "0  83.647%  \n",
       "0  85.539%  \n",
       "0  82.304%  \n",
       "0  85.809%  \n",
       "0  85.449%  \n",
       "0  81.483%  \n",
       "0  78.704%  \n",
       "0  81.616%  \n",
       "0  81.217%  \n",
       "0  85.261%  \n",
       "0  82.267%  \n",
       "0  84.084%  \n",
       "0  85.153%  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desempenhoDosModelos = pd.DataFrame()\n",
    "for nomeBase in bases.keys():\n",
    "    covidData = mf.carregarBase(bases[nomeBase], True, colunasRemovidas)\n",
    "    x_train, x_test, y_train, y_test = mf.criarTreinamentoTeste(0.3, covidData, alvo)\n",
    "    \n",
    "    for nomeModelo in modelos.keys():\n",
    "\n",
    "        modelo = mf.criarModelo(nomeModelo, modelos[\"AB\"])\n",
    "        baseMap = {'Base': nomeBase, 'Modelo': nomeModelo, 'Hiperparâmetros': modelo.get_params()}\n",
    "\n",
    "        metricasMap = mf.calcularMetricas(x_train, x_test, y_train, y_test, covidData, modelo)\n",
    "        kfoldsMap = mf.calcularKfolds(covidData, alvo, modelo)\n",
    "        desempenhoDosModelos = juntarBases (desempenhoDosModelos, converterMapas(baseMap, metricasMap, kfoldsMap))\n",
    "    \n",
    "desempenhoDosModelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86890111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write = pd.ExcelWriter(\"desempenho-modelos.xlsx\")\n",
    "desempenhoDosModelos.to_excel(write, 'dados', index = False)\n",
    "write.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([mapa])\n",
    "\n",
    "# minhaBase = pd.DataFrame(mapa ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd54c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
